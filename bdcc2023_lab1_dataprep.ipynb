{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503703db",
   "metadata": {},
   "source": [
    "# <center style=\"color: #FF5A60\"> Unveiling the Shifting Landscape of Airbnb:<br>Understanding Supply, Demand, and Pricing Dynamics </center> <a class='tocSkip'>\n",
    "    \n",
    "This notebook is dedicated for the details of the data collection and cleaning process that serves as a supplementary to the main report of this project.\n",
    "    \n",
    "**! Note:** Rerunning this whole notebook, especially the cells under the `Code` section, is not advisable as this would (1) overwrite the current files generated, and (2) take almost 2 days to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844e14a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T22:05:36.742738Z",
     "start_time": "2023-05-15T22:05:32.096514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/15 22:05:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local[*]')\n",
    "         .config('spark.sql.execution.arrow.pyspark.enabled', 'true')\n",
    "         .getOrCreate())\n",
    "spark.sparkContext.setLogLevel('OFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28d953",
   "metadata": {},
   "source": [
    "## I. Background\n",
    "\n",
    "The analysis looks at the availability and pricing of listings in Airbnb from 2019-2021 across 10 countries namely: France, Italy, Spain, United Kingdom, United States, Belgium, South Africa, Ireland, Switzerland, and Japan. This information is found in their database's **calendar dataset**.\n",
    "\n",
    "\n",
    "**Challenges**\n",
    "\n",
    "The data cleaning and preprocessing pipeline were motivated by these 5 challenges:\n",
    "\n",
    "1. As detailed in [`Inside Airbnb`](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=150111846)'s official data dictionary, the calendar dataset was revised in 2019 to add new features such as `adjusted_price`, `minimum_nights`, and `maximum_nights`. This change introduced complexities when merging files across different countries, states, and years since the new features could be absent in one file while present in the other.\n",
    "<br>\n",
    "\n",
    "2. The calendar dataset does not have details on the location of the listing so deriving this information from another source is needed for the comparative analysis on different countries.\n",
    "<br>\n",
    "\n",
    "3. Some of the files are malformed having unescaped quotes or inconsistent use of delimiter as an escape character. This resulted in an error when loading data in the same year, country, or state in bulk since some would have a different data structure than others.\n",
    "<br>\n",
    "\n",
    "4. Some of the fields in a file need to be transformed into a different data type first before mathematical operations can be applied. For example, `price` is read as a string instead of a number since it has characters indicating currency such as dollar signs, commas, and periods. Moreover, other fields such as `minimum_nights` and `maximum_nights` are also read as a string due to missing value tags such as \"None\".\n",
    "<br>\n",
    "\n",
    "5. A total of around 21.8Gb data was used in this project and the data for a whole year has billions of rows. Due to this, data transformations take a long time to run and operations were done inefficiently. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccce0701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T22:06:40.186790Z",
     "start_time": "2023-05-15T22:05:36.749051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample set of the calendar dataset's 2020 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "      <th>adjusted_price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106052</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>f</td>\n",
       "      <td>$66.00</td>\n",
       "      <td>$66.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>f</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>30</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>f</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>30</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>f</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>30</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>2020-12-19</td>\n",
       "      <td>f</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>30</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       date available    price adjusted_price  minimum_nights  maximum_nights\n",
       "0      106052 2020-12-17         f   $66.00         $66.00               5            1125\n",
       "1         109 2020-12-16         f  $115.00        $115.00              30             730\n",
       "2         109 2020-12-17         f  $115.00        $115.00              30             730\n",
       "3         109 2020-12-18         f  $115.00        $115.00              30             730\n",
       "4         109 2020-12-19         f  $115.00        $115.00              30             730"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"A sample set of the calendar dataset's 2020 files\")\n",
    "t1 = ps.read_csv(\n",
    "    '/mnt/data/public/insideairbnb/data.insideairbnb.com/united-states/'\\\n",
    "    'ca/los-angeles/2020-12-15/data/calendar.csv.gz'\n",
    "    )\n",
    "t1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b924f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T22:06:47.190142Z",
     "start_time": "2023-05-15T22:06:40.189770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total file size of the data used:\n",
      "22G\ttotal\n"
     ]
    }
   ],
   "source": [
    "print('Total file size of the data used:')\n",
    "! du -sch --total \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/france/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/italy/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/spain/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/united-kingdom/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/united-states/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/belgium/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/south-africa/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/ireland/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/switzerland/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/japan/*/*/2019*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/france/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/italy/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/spain/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/united-kingdom/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/united-states/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/belgium/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/south-africa/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/ireland/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/switzerland/*/*/202[0-1]*/data/calendar.csv.gz \\\n",
    "/mnt/data/public/insideairbnb/data.insideairbnb.com/japan/*/*/202[0-1]*/data/calendar.csv.gz | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defe427",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "To address these challenges, the following steps were done:\n",
    "\n",
    "1. The data was collected per country and year instead of reading the whole in one go to ensure that the files accessed would have the same data structure.\n",
    "<br>\n",
    "\n",
    "2. The country where the listings are located was inferred from the name of the directory where the file being read is. For example, given the file path: `/mnt/data/public/insideairbnb/data.insideairbnb.com/united-states/ca/*/2020*/data/calendar.csv.gz`, the country was determined by separating the name by the backslash ('/') character then getting the 6th token.\n",
    "<br>\n",
    "\n",
    "3. Malformed files and rows in the dataset were skipped and dropped, respectively to ensure the information read was consistent and usable for analysis.\n",
    "<br>\n",
    "\n",
    "4. Extra characters were removed and tags for missing values were standardized to have Numpy's `np.nan` as their value for consistency, allowing the fields to be read in their expected data types.\n",
    "<br>\n",
    "\n",
    "5. The dataset was loaded in batches based on the country and year in the listing date. From CSV files, each batch was then converted to Parquet files to facilitate more efficient processing when doing transformations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26947ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T22:06:53.265821Z",
     "start_time": "2023-05-15T22:06:47.195785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample set of the calendar dataset's 2020 files after cleaning and preprocessing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "      <th>adjusted_price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38585</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>f</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>February</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6004216</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>t</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>February</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6004216</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>t</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>March</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6004216</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>t</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>March</td>\n",
       "      <td>Monday</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6004216</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>t</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>March</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       date available  price  adjusted_price  minimum_nights  maximum_nights  year     month dayofweek        country\n",
       "0       38585 2020-02-29         f   50.0            50.0             1.0             3.0  2020  February  Saturday  United States\n",
       "1     6004216 2020-02-29         t   50.0            50.0             1.0             7.0  2020  February  Saturday  United States\n",
       "2     6004216 2020-03-01         t   50.0            50.0             1.0             7.0  2020     March    Sunday  United States\n",
       "3     6004216 2020-03-02         t   48.0            48.0             1.0             7.0  2020     March    Monday  United States\n",
       "4     6004216 2020-03-03         t   48.0            48.0             1.0             7.0  2020     March   Tuesday  United States"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"A sample set of the calendar dataset's 2020 files after cleaning \" \\\n",
    "      \"and preprocessing:\")\n",
    "t2 = ps.read_parquet(\n",
    "    '/mnt/processed/private/msds2023/cpt1/airbnb_data/calendar/2020/'\\\n",
    "    'united-states/part-00000-6aab4765-7dfc-4d05-8b1e-c86ca17b85c9-c000.snappy.parquet/'\n",
    "    )\n",
    "t2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229520b6",
   "metadata": {},
   "source": [
    "## II. Code\n",
    "\n",
    "The following code blocks are used to collect and clean the data needed for this project. The countries and year to be processed and the expected data types per column were first defined. If the country has not been processed yet, the code would proceed. Otherwise, skip to the next one until done.\n",
    "\n",
    "Malformed files and rows were also skipped when reading the data in bulk. Correctly formatted files were then cleaned by removing extra characters that would hinder them from being processed as the expected data type (e.g., converting `str` to `float` or `int`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4085ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T22:02:57.887950Z",
     "start_time": "2023-05-15T22:02:57.873053Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the countries to be processed\n",
    "countries = ['belgium', 'ireland', 'japan', 'switzerland', 'france',\n",
    "             'italy', 'spain', 'united-kingdom', 'united-states']\n",
    "\n",
    "# define the data types of each column in the dataset\n",
    "col_dtypes = {'listing_id': int, 'price': str, 'adjusted_price': str,\n",
    "              'minimum_nights': str, 'maximum_nights': str}\n",
    "col_dates = ['date']\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Return the dataframe with extra characters removed, standardized\n",
    "    missing value tags, and additional information on the listing's\n",
    "    country location. \n",
    "    \"\"\"\n",
    "    df2 = (df\n",
    "             .assign(available=df.available.replace({'N/A': np.nan, \n",
    "                                                     'None': np.nan}),\n",
    "                     minimum_nights=df.minimum_nights\n",
    "                                        .replace({'N/A': np.nan, \n",
    "                                                  'None': np.nan})\n",
    "                                        .astype(float),\n",
    "                     maximum_nights=df.maximum_nights\n",
    "                                        .replace({'N/A': np.nan, \n",
    "                                                  'None': np.nan})\n",
    "                                        .astype(float),\n",
    "                     price=df.price.replace({'N/A': np.nan,\n",
    "                                             'None': np.nan,\n",
    "                                             ',': ''})\n",
    "                                   .str.strip('$').astype(float),\n",
    "                     adjusted_price=df.adjusted_price\n",
    "                                      .replace({'N/A': np.nan,\n",
    "                                               'None': np.nan,\n",
    "                                               ',': ''})\n",
    "                                      .str.strip('$').astype(float),\n",
    "                     year=df.date.dt.year.astype('int32'),\n",
    "                     month=df.date.dt.month_name(),\n",
    "                     dayofweek=df.date.dt.day_name()\n",
    "                    )  \n",
    "    )\n",
    "    df2['country'] = f.split('/')[6].replace('-', ' ').title()\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff9085",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-15T22:01:33.098Z"
    }
   },
   "outputs": [],
   "source": [
    "# added to remove printed warnings and save on memory\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# stores the country and year when an error is encountered\n",
    "error = []\n",
    "# stores countries that has already been processed\n",
    "done = []\n",
    "# defines the years to be processed\n",
    "year = [2019, 2020 , 2021]\n",
    "\n",
    "for idx, c in enumerate(countries):\n",
    "    \n",
    "    # checks if country has already been processed\n",
    "    if c not in done:\n",
    "        \n",
    "        print(f'{idx}: {c}')\n",
    "        for y in year:\n",
    "            print(y)\n",
    "            f = '/mnt/data/public/insideairbnb/data.insideairbnb.com/'\\\n",
    "                f'{c}/*/*/{y}*/data/'\\\n",
    "                'calendar.csv.gz'\n",
    "\n",
    "            # try reading the files per country and year\n",
    "            try:\n",
    "                psdf = ps.read_csv(f, sep=\",\", multiLine=True, mode=\"DROPMALFORMED\",\n",
    "                                   escapechar='\"', quotechar='\"',\n",
    "                                   dtypes=col_dtypes)\n",
    "\n",
    "                # clean the data\n",
    "                psdf2 = clean_data(psdf)\n",
    "\n",
    "                # define path for saving\n",
    "                ctry = f.split('/')[6] \n",
    "                path = f'/mnt/processed/private/msds2023/cpt1/airbnb_data/calendar/{y}/'\n",
    "                out_fname = f'{ctry}'\n",
    "\n",
    "                # save to parquet\n",
    "                (psdf2.to_parquet(path+out_fname, mode='overwrite'))\n",
    "\n",
    "            # skip the file if an error is encountered and log it\n",
    "            except:\n",
    "                print(f'Error: {c}--{y}')\n",
    "                error.append([c, y])\n",
    "                continue\n",
    "\n",
    "        done.append(c)\n",
    "    \n",
    "    # skips the country if it has already been processed\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f290c1",
   "metadata": {},
   "source": [
    "-End of Data Preparation Notebook-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
